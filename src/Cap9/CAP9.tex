%-----------------------------------------------------------------------------------------------------------------
\chapter[Conclusão e trabalho futuro]{Conclusão e trabalho futuro}
\label{Ch:Conclusao}

\section{Conclusão}

 \hspace{1cm}O impacto positivo esperado através da utilização da \textit{pipeline} é notório principalmente na redução do tempo total de validação da qualidade do código para acelerar o processo de colocação em produção. A automatização dos testes e a \textit{framework} apresentada (\textbf{xUnit}) como alternativa são mais céleres na execução dos testes quando comparadas com a \textit{framework} atualmente em utilização na empresa. Com a implementação dos testes unitários em \textbf{xUnit} é possível obter-se uma redução para quase metade do tempo na sua execução e, ao ser acrescentada na \textit{pipeline} de testes, liberta-se o \textit{developer} para a realização de outras tarefas enquanto a \textit{suite} de testes está a decorrer. Esta melhoria aplica-se não só na execução dos testes unitários, mas também na execução dos testes de integração e performance.
 
 \hspace{1cm}A análise estática é um processo um pouco mais demorado, sendo que o serviço em si, necessita de alguma configuração inicial, que tanto pode ser feita \textit{on demand}, como pré-configurada. A primeira abordagem tem a vantagem de não necessitar de nenhum recurso físico. Tudo o que é necessário é gerado na \textit{pipeline} com recurso a \textit{containers docker}, no entanto, é necessário lançar a imagem em cada execução da \textit{pipeline}, gerar a chave com o projeto -- processo que pode demorar até 3 minutos em \textit{setup} -- e dependendo do tamanho do projeto, vários minutos a analisar, sendo que neste caso demorou em média 5 minutos. A segunda abordagem requer que o serviço esteja configurado numa máquina (física ou virtual), no entanto permite reduzir o tempo de \textit{setup} e de análise devido a estratégias de \textit{cache} realizadas pelo \textbf{SonarQube}. De qualquer das formas, apesar de esta análise ser um pouco demorada, em termos práticos esta execução não vai afetar a utilidade da \textit{pipeline}, pelo contrário, uma vez que ela pode ser configurada para ser executada em paralelo ao processo de testes e assim apresentar feedback informativo sobre o projeto em si.
 
  \hspace{1cm}A utilização de \textit{containers} para a validação de aplicações também representa uma melhoria significativa em termos de tempo. O processo de \textit{deploy} manual de uma aplicação numa máquina de \textit{staging} para validação do PO (\textit{product owner}) ou do cliente é mais demorado e implica a existência de uma máquina para onde será feito o \textit{deploy}. Esta abordagem pode trazer problemas em termos de dependências uma vez que a atualização dos serviços é manual, podendo ficar alguma dependência por atualizar causando problemas no serviço. O \textit{deploy} de uma aplicação para vários \textit{containers} pode ser visto como uma forma mais fácil e eficaz de manter a aplicação e os serviços que a compõem, e resolve a problemática de dependências e versões antigas uma vez que toda a infraestrutura é construída apenas para aquela versão de código. 
 
 \hspace{1cm}Tendo em conta todos os fatores que podem ser considerados para a redução do tempo de entrega, a empresa pode reduzir o tempo de execução dos testes unitários, de integração e de performance para aproximadamente metade (50\%). Caso a execução dos testes consuma 10 minutos por execução, e assumindo a execução completa de testes 2 vezes por dia -- o que é bastante inferior à realidade mas muitas das execuções dos testes são apenas parciais -- estaríamos a falar de uma redução diária de 10 minutos, o que se transforma em reduções mensais de quase 4 horas (isto para apenas um \textit{developer}). Tendo em conta que o projeto tem entre 2-3 \textit{developers}, as poupanças de tempo sobem para dias de tempo poupado. Mas na realidade, o uso de uma \textit{pipeline} leva a uma poupança de tempo muito superior, como a execução dos testes e as análises realizadas são feitas de modo assíncrono ao trabalho do \textit{developer}, ele não fica bloqueado à espera que o processo termine, ficando assim livre para continuar as suas tarefas, sendo notificado e apenas tomando acções quando os resultados dos testes falham.
 
  \hspace{1cm}Os \textit{deploys} de artefactos, de imagens e da aplicação também são um facto que contribui diretamente para a redução do tempo de entrega. O \textit{deploy} de um artefacto para um repositório de artefactos é relativamente simples, no entanto, pode ser necessário consultar documentação para fazer este processo manualmente. O mesmo acontece com o \textit{deploy} de uma imagem para um registo privado de imagens e com a \textit{containerização} de uma aplicação para aprovação. Quando automatizado, este processo reduz imenso tempo à validação do software para produção que, por sua vez, reduz o \textit{time-to-market} que normalmente estaria dependente de um \textit{deploy} manual sempre sujeito a erros. Apesar de ser difícil prever com exatidão, no cenário mais pessimista a \textit{pipeline} de testes automatizados poderia reduzir anualmente em entre 18 horas e meia e 2 dias e 5 horas ao tempo de desenvolvimento de cada serviço -- somando ainda as reduções inerentes à automatização dos \textit{deploys} -- e ao tempo de entrega de software, não esquecendo a redução nas falhas na execução manual de instruções onde é propícia a ocorrência de falha humana. Este valor foi obtido através da multiplicação daquilo que são considerados os principais fatores de redução do tempo de entrega pelo número total de dias úteis anuais em comparação com o processo atual de teste e validação de código para produção.
 
 \hspace{1cm}A dinâmica criada pelo sistema de visualização também tem um impacto global no tempo de execução da \textit{pipeline}. Com feedback em tempo real, a equipa de desenvolvimento vai monitorizar constantemente o desenvolvimento das aplicações. Pode ainda concluir-se que a utilização do sistema de visualização iria contribuir para a redução do \textit{time-to-market}, através do aumento do \textit{awareness} global, apesar de ser difícil estimar um número em quantidades de tempo. Através da ajuda das ferramentas de análise da qualidade do código os \textit{developers} terão uma ideia mais concreta sobre o desenvolvimento e a manutenção das aplicações mais facilitada, podendo identificar e corrigir as falhas com maior rapidez.
 
 \section{Trabalho futuro}
 
 \hspace{1cm}Para este trabalho consideraram-se apenas os componentes indispensáveis para que o \textit{workflow} seja semelhante ao de uma \textit{pipline} de integração e entrega contínua. Dos componentes mencionados no documento, aqueles que podem ser considerados essenciais para o funcionamento de uma \textit{pipeline} de testes automatizados são:
 
\begin{itemize}
 \item O orquestrador de processos;
 \item O \textit{version control system};
 \item A \textit{tool} de análise estática;
 \item O repositório de artefactos;
 \item O repositório de imagens;
 \item O mecanismo de \textit{load-balancing};
 \item A \textit{tool} de containerização;
 \item A \textit{tool} de comunicação interna;
\end{itemize}

\hspace{1cm}Dependendo da complexidade do processo de análise da qualidade do código e da validação do código para produção, podem ser adicionados outros componentes, quer durante a fase de validação, na \textit{pipeline}, quer depois de validado o software, já na fase de produção. Por este motivo, existem várias linhas de melhoria deste projeto que podem ser seguidas pela empresa no sentido de aumentar tanto a celeridade no desenvolvimento como a resiliência e a eficácia na resolução de problemas que possam surgir em produção. 

\hspace{1cm}Executar todos os testes unitários existentes, criar testes de integração e performance na plataforma \textit{Yugoup} seria, evidentemente, o próximo passo para dar continuidade ao trabalho desenvolvido pela equipa. Numa fase de transição para testes de integração automatizados poderiam também ser executadas baterias de testes de integração gerados automaticamente (em nUnit) através da utilização do \textbf{Swagger Codegen} (https://swagger.io/tools/swagger-codegen/). 

\hspace{1cm}Podem ser incluídos na \textit{pipeline} \textit{smoke tests} à plataforma através da utilização de ferramentas como o \textbf{Katalon Studio} (https://www.katalon.com/) ou mesmo o \textbf{Selenium} (https://www.seleniumhq.org/). A criação destes testes não é exigente em termos desenvolvimento uma vez que são gerados automaticamente através de uma metodologia de \textit{recording} dos casos de testes, permitindo uma posterior replicação num ciclo de extenso de tentativas. Isto seria útil para testar a resistência da plataforma a, por exemplo, submissões consecutivas de pedidos de consulta, ou até mesmo a submissões consecutivas de dados.

\hspace{1cm}No que diz respeito à produção e análise de versões executáveis de uma aplicação, outro dos caminhos seria o \textit{upgrade} do \textbf{Nexus Repository Manager} para a versão mais atualizada e a utilização do \textbf{Dive}. Tendo em vista a melhoria contínua da performance da \textit{pipeline}, é importante mencionar que a versão do repositório de artefactos utilizada (versão 2) apenas suporta a inclusão de um mecanismo de armazenamento de artefactos -- neste caso em particular de \textit{NuGet packages}. No entanto a versão mais recente do \textbf{Nexus Repository Manager} já suporta o armazenamento de imagens Docker. Por sua vez, o \textbf{Docker Dive} pode ser utilizado como uma ferramenta de análise das camadas de uma imagem, com o objetivo de encontrar novas formas para comprimir o seu tamanho final. 

\hspace{1cm}Como os projetos também falham mesmo depois de todos os testes serem bem sucedidos, em produção faz sentido utilizar as ferramentas de monitorização de plataformas, tanto para monitorizar os pedidos dos utilizadores como os dados das consultas ou das bases de dados da plataforma. Aconselha-se para isso a utilização do \textbf{ELK Stack} (https://www.elastic.co/pt/elk-stack) que inclui o \textit{Kibana}, o \textit{Elasticsearch}, o \textit{Logstash} e o \textit{Beats}. Existe também a possibilidade de utilização do \textbf{Nagios} (https://www.nagios.org/) para monitorizar o estado da infraestrutura utilizada em tempo real. Estas ferramentas vão produzir gráficos que podem ser consultados e analisados pelo \textit{business}, com dados reais e em tempo real, sobre as consultas, vendas, ou o que quer que seja útil em termos de dados sobre a utilização da plataforma, mesmo a nível técnico. Para monitorização e \textit{caching} de dados pode ser estudada a utilização do \textbf{Redis} (https://redis.io/) a fim de reduzir a carga sobre a base de dados. Outra possibilidade de migração será a mudança de base de dados do motor \textbf{Microsoft SQL Server} para uma outra que seja Open source, uma vez que vai diminuir os custos signigicativamente. Existe a opção de migração para bases de dados em \textbf{PostGreSQL} (https://www.postgresql.org/) uma vez que é compatível com o \textbf{.NET  Entity Framework Core} e integra facilmente com as \textit{Web APIs} desenvolvidas, não sendo necessária modificações significativas no projecto.
